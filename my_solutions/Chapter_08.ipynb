{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1\n",
    "W przypadku dużej wielowymiarowości normalnie spotykane zbiory okazują się rzadkie. Zmniejszając wymiarowość tracimy przeważnie część informacji, ale drastycznie zmniejszamy czas potrzebny na wytrenowanie modelu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2\n",
    "To co wyrzej - zbiory są rzadkie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3\n",
    "Proces jest odwracalny jedynie w przypadku gdy zredukowany zbiór zachowuje 100% wariancji zbioru pierwotnego. Przeważnie nie jest to możliwe, ponieważ przeprowadzając redukcję chcemy utracić część nieznaczących informacji kosztem rozmiaru danych. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4\n",
    "A możemy, czemu nie? Inne pytanie czy coś to da. PCA wykrywa kierunki główne, więc liniowe zależności pomiędzy danymi. Jeżeli zależności są bardzo nieliniowe to wykryte kierunki główne będą objaśniały małą część danych. W rezultacie może się okazać, że chcąc zachować np 95% wariancji osiągniemy niezauważalną redukcję wymiarów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5\n",
    "Nie rozumiem tego pytania."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6\n",
    "- Klasyczna - w większości przypadków\n",
    "- Przyrostowa - gdy dane nie mieszczą się w pamięci\n",
    "- Losowa - \n",
    "- Jądrowa - gdy mamy doczynienia z poskręcaną rozmaitością"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7\n",
    "Można badać odległość próbki oryginalnej od przeciwobrazu rekonstrukcji.\n",
    "\n",
    "Można także zbudować dwa modele, przed i po redukcji. Jeżęli wydajność modeli nie uległa dużej zmianie oznacza to że nie utraciliśmy dużo informacji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8\n",
    "Chyba nie ma - **źle**\n",
    "\n",
    "Jednak ma sens. Na początek można zastosować szybszy algorytm PCA, a następnie wolniejszy LLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9\n",
    "MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(mnist['data'], mnist['target'], train_size=60_000)\n",
    "\n",
    "\n",
    "def measure_train_time(model, X_train, y_train):\n",
    "    time_start = dt.datetime.now()\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    time_end = dt.datetime.now()\n",
    "    print(f'Trening ended. Elapsed time: {time_end - time_start}')\n",
    "\n",
    "    \n",
    "def get_model_accuracy(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f'Model accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trening ended. Elapsed time: 0:00:36.657597\n",
      "Model accuracy: 0.9658\n"
     ]
    }
   ],
   "source": [
    "#No PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier()\n",
    "measure_train_time(rf_clf, X_train, y_train)\n",
    "get_model_accuracy(rf_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trening ended. Elapsed time: 0:01:37.888574\n",
      "Model accuracy: 0.9439\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "rf_clf = RandomForestClassifier()\n",
    "measure_train_time(rf_clf, X_train_pca, y_train)\n",
    "get_model_accuracy(rf_clf, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10\n",
    "t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wilylynx/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "X_trans = TSNE(n_components=2).fit_transform(mnist['data'])\n",
    "X_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,5))\n",
    "plt.scatter(X_trans[:,0], X_trans[:,1], label=mnist['target']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
